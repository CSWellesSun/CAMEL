{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compression_make_causal_mask(\n",
    "    input_ids_shape: torch.Size,\n",
    "    dtype: torch.dtype,\n",
    "    device: torch.device,\n",
    "    past_key_values_length: int = 0,\n",
    "    window_size=4,\n",
    "):\n",
    "    bsz, tgt_len = input_ids_shape\n",
    "    mask = torch.full((tgt_len, tgt_len), torch.finfo(dtype).min, device=device)\n",
    "    mask_cond = torch.arange(mask.size(-1), device=device)\n",
    "    mask.masked_fill_(mask_cond < (mask_cond + 1).view(mask.size(-1), 1), 0)\n",
    "    mask = mask.to(dtype)\n",
    "    if past_key_values_length > 0:\n",
    "        mask = torch.cat(\n",
    "            [\n",
    "                torch.zeros(\n",
    "                    tgt_len, past_key_values_length, dtype=dtype, device=device\n",
    "                ),\n",
    "                mask,\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "    block_mask = (\n",
    "        torch.arange(past_key_values_length + tgt_len, device=device).unsqueeze(0)\n",
    "        // window_size\n",
    "    )\n",
    "    block_mask = block_mask != block_mask.T\n",
    "    casual_block_mask = torch.logical_or(\n",
    "        mask, block_mask[past_key_values_length : past_key_values_length + tgt_len, :]\n",
    "    )\n",
    "    mask = torch.where(casual_block_mask, torch.finfo(dtype).min, 0)\n",
    "    mask = mask[None, None, :, :].expand(bsz, 1, -1, -1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4028e+38],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _speculation_make_causal_mask(\n",
    "    input_ids_shape: torch.Size,\n",
    "    dtype: torch.dtype,\n",
    "    device: torch.device,\n",
    "    past_seen_compress_token: int = 0,\n",
    "    window_size: int = 4,\n",
    "    key_value_length: int = 0,\n",
    "    speculation_length: int = 0,\n",
    "):\n",
    "    bsz, tgt_len = input_ids_shape\n",
    "    mask = torch.full((tgt_len, tgt_len), torch.finfo(dtype).min, device=device)\n",
    "    mask_cond = torch.arange(mask.size(-1), device=device)\n",
    "    mask.masked_fill_(mask_cond < (mask_cond + 1).view(mask.size(-1), 1), 0)\n",
    "    mask = mask.to(dtype)\n",
    "    if past_seen_compress_token < key_value_length:\n",
    "        # prefill, TODO: need to optimize\n",
    "        block_mask = torch.arange(tgt_len, device=device).unsqueeze(0) // window_size\n",
    "        block_mask = block_mask != block_mask.T\n",
    "        casual_block_mask = torch.logical_or(mask, block_mask)\n",
    "        mask = torch.where(casual_block_mask, torch.finfo(dtype).min, 0)\n",
    "    if speculation_length > 0:\n",
    "        speculaiton_mask = torch.zeros(\n",
    "            (tgt_len, speculation_length), dtype=dtype, device=device\n",
    "        )\n",
    "        mask = torch.cat([speculaiton_mask, mask], dim=-1)\n",
    "    key_value_length += past_seen_compress_token\n",
    "    if key_value_length > 0:\n",
    "        kv_mask = torch.full(\n",
    "            (tgt_len, key_value_length), torch.finfo(dtype).min, device=device\n",
    "        )\n",
    "        q_position_id = torch.arange(\n",
    "            past_seen_compress_token * window_size,\n",
    "            past_seen_compress_token * window_size + tgt_len,\n",
    "            device=device,\n",
    "        )\n",
    "        kv_position_id = torch.arange(\n",
    "            window_size - 1,\n",
    "            key_value_length * window_size,\n",
    "            step=window_size,\n",
    "            device=device,\n",
    "        )\n",
    "        kv_mask.masked_fill_(q_position_id.view(-1, 1) > kv_position_id, 0).to(dtype)\n",
    "        mask = torch.cat([kv_mask, mask], dim=-1)\n",
    "    mask = mask[None, None, :, :].expand(bsz, 1, -1, -1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# prefill\n",
    "_speculation_make_causal_mask(\n",
    "    torch.Size((1, 3)),\n",
    "    dtype=torch.float32,\n",
    "    device=\"cpu\",\n",
    "    past_seen_compress_token=0,\n",
    "    window_size=2,\n",
    "    key_value_length=1,\n",
    "    speculation_length=0,\n",
    ")\n",
    "\n",
    "# decode\n",
    "_speculation_make_causal_mask(\n",
    "    torch.Size((1, 1)),\n",
    "    dtype=torch.float32,\n",
    "    device=\"cpu\",\n",
    "    past_seen_compress_token=1,\n",
    "    window_size=2,\n",
    "    key_value_length=0,\n",
    "    speculation_length=0,\n",
    ")\n",
    "\n",
    "# tree_decode\n",
    "_speculation_make_causal_mask(\n",
    "    torch.Size((1, 3)),\n",
    "    dtype=torch.float32,\n",
    "    device=\"cpu\",\n",
    "    past_seen_compress_token=1,\n",
    "    window_size=2,\n",
    "    key_value_length=0,\n",
    "    speculation_length=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camel-u_X7orLA-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
